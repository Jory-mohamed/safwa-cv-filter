import streamlit as st
import pdfplumber
import docx2txt
from rapidfuzz import fuzz
from io import BytesIO

st.set_page_config(page_title="ุตููุฉ ููุฑุฒ ุงูุณูุฑ ุงูุฐุงุชูุฉ", layout="centered")
st.title("๐ ุตููุฉ ููุฑุฒ ุงูุณูุฑ ุงูุฐุงุชูุฉ")
st.caption("ุชูููุฒ ุจุฎุทูุฉ โ ูุณุฎุฉ ูุญุณููุฉ")

# ---------------- ุฏูุงู ูุณุงุนุฏุฉ ----------------
def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = text.lower()
    text = text.replace("ุฉ","ู").replace("ุฃ","ุง").replace("ุฅ","ุง").replace("ุข","ุง")
    text = "".join(ch for ch in text if ch.isalnum() or ch.isspace())
    return text

def extract_text(file) -> str:
    text = ""
    if file.name.endswith(".pdf"):
        try:
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    text += page.extract_text() or ""
        except:
            text = ""
    elif file.name.endswith(".docx"):
        try:
            text = docx2txt.process(file)
        except:
            text = ""
    return normalize_text(text)

def best_score(needle: str, haystack: str) -> int:
    """ูุณุชุฎุฏู token_sort_ratio ุนุดุงู ููุงุฑู ุญุชู ูู ุงููููุงุช ูุชูุฎุจุทุฉ"""
    if not needle:
        return 100
    n = normalize_text(needle)
    h = normalize_text(haystack)
    return fuzz.token_sort_ratio(n, h)

def nationality_synonyms(nation: str):
    """ูุฑุงุฏูุงุช ุงูุฌูุณูุฉ"""
    n = normalize_text(nation)
    if not n:
        return []
    if "ุบูุฑ" in n or "ูุงูุฏ" in n or "non" in n:
        return ["ุบูุฑ ุณุนูุฏู","ุบูุฑุณุนูุฏู","non saudi","nonsaudi","expat","ูุงูุฏ"]
    return ["ุณุนูุฏู","ุณุนูุฏูู","saudi","ksa","saudi arabia"]

# ---------------- ุงููุงุฌูุฉ ----------------
col1, col2 = st.columns(2)
with col1:
    university_input = st.text_input("ุงูุฌุงูุนุฉ", placeholder="ูุซุงู: ุฌุงูุนุฉ ุงูููู ุณุนูุฏ")
with col2:
    major_input = st.text_input("ุงูุชุฎุตุต", placeholder="ูุซุงู: ูุธู ูุนูููุงุช ุฅุฏุงุฑูุฉ")

nation_input = st.text_input("ุงูุฌูุณูุฉ", placeholder="ูุซุงู: ุณุนูุฏู")

uploaded_file = st.file_uploader("โจ ุงุฑูุน ุณูุฑุชู ุงูุฐุงุชูุฉ (PDF ุฃู DOCX)", type=["pdf","docx"])

THRESH = 80  # ุซุงุจุช

if uploaded_file is not None:
    text = extract_text(uploaded_file)

    uni_score = best_score(university_input, text)
    major_score = best_score(major_input, text)

    nat_scores = []
    if nation_input.strip():
        for syn in nationality_synonyms(nation_input):
            nat_scores.append(best_score(syn, text))
    else:
        nat_scores = [100]
    nation_score = max(nat_scores)

    # ุนุฑุถ ุงููุชุงุฆุฌ
    colA, colB, colC = st.columns(3)
    colA.metric("ุงูุฌุงูุนุฉ", f"{uni_score}%")
    colB.metric("ุงูุชุฎุตุต", f"{major_score}%")
    colC.metric("ุงูุฌูุณูุฉ", f"{nation_score}%")

    if all([uni_score>=THRESH, major_score>=THRESH, nation_score>=THRESH]):
        st.success(f"โ ูุทุงุจู ููุดุฑูุท: {uploaded_file.name}")
    else:
        st.error(f"โ ุบูุฑ ูุทุงุจู (ุฃุญุฏ ุงูุดุฑูุท ุฃูู ูู {THRESH}%)")