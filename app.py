import streamlit as st
import re, unicodedata, io, os
from pypdf import PdfReader
from rapidfuzz import fuzz
import pandas as pd

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="ÙÙ„ØªØ±Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©", page_icon="ğŸ—‚ï¸", layout="wide")
st.title("ğŸ—‚ï¸ ÙÙ„ØªØ±Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©")
st.caption("Version: 3.1.1 â€¢ ÙŠØ¯Ø¹Ù… PDF + Excel + CSV â€¢ Ø¹ØªØ¨Ø© Ø«Ø§Ø¨ØªØ© 80 â€¢ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ â€¢ Ø¯Ø¹Ù… Ø§Ù„Ù„ÙˆÙ‚Ùˆ")

# ===== Ø¹Ø±Ø¶ Ø§Ù„Ù„ÙˆÙ‚Ùˆ Ø¥Ù† ÙˆÙØ¬Ø¯ =====
def show_logo():
    for path in ("logo.png", "assets/logo.png", "static/logo.png"):
        if os.path.exists(path):
            try:
                st.image(path, width=140)
            except Exception:
                pass
            break
show_logo()

# ===== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© =====
def normalize_ar(text: str) -> str:
    if not text:
        return ""
    text = text.lower()
    text = ''.join(ch for ch in unicodedata.normalize('NFKD', text) if not unicodedata.combining(ch))
    text = re.sub(r"[Ø£Ø¥Ø¢Ù±]", "Ø§", text)
    text = text.replace("Ø©","Ù‡").replace("Ù‰","ÙŠ")
    text = re.sub(r"[^0-9a-z\u0600-\u06FF\s]+", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def extract_pdf_text(file_bytes: bytes) -> str:
    reader = PdfReader(io.BytesIO(file_bytes))
    pages = []
    for p in reader.pages:
        try:
            pages.append(p.extract_text() or "")
        except Exception:
            pages.append("")
    return "\n".join(pages)

def fuzzy_match(term: str, text: str, threshold: int = 80) -> (bool, int):
    if not term or not term.strip():
        return None, 0
    norm_text = normalize_ar(text)
    norm_term = normalize_ar(term)
    score1 = fuzz.partial_ratio(norm_term, norm_text)
    score2 = fuzz.token_set_ratio(norm_term, norm_text)
    score = max(score1, score2)
    return (score >= threshold), int(score)

# ===== Ø§Ù„ØªØ­Ù‚Ù‚ =====
def evaluate_cv(text_raw: str, uni_req, major_req, major_syn, nat_req, threshold: int = 80):
    norm_text = normalize_ar(text_raw)

    # Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© ÙˆØ§Ù„Ø¬Ù†Ø³ÙŠØ©: Fuzzy
    uni_ok, uni_score = fuzzy_match(uni_req, norm_text, threshold)
    nat_ok, nat_score = fuzzy_match(nat_req, norm_text, threshold)

    # Ø§Ù„ØªØ®ØµØµ: Fuzzy + Ù…Ø±Ø§Ø¯ÙØ§Øª + ÙƒÙ„Ù…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©
    major_ok, major_score = fuzzy_match(major_req, norm_text, threshold)
    syn_hits = []

    if major_syn.strip():
        for s in major_syn.split(","):
            term = s.strip()
            if not term:
                continue
            ok, score = fuzzy_match(term, norm_text, threshold)
            if ok:
                major_ok = True
                major_score = max(major_score, score)
                syn_hits.append(f"{term} (score={score})")

    # ÙƒÙ„Ù…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©
    base_keywords = ["Ù†Ø¸Ù…", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"]
    kw_hits = [kw for kw in base_keywords if kw in norm_text]
    if len(kw_hits) >= 2:
        major_ok = True
        major_score = max(major_score, 90)
        syn_hits.append(" + ".join(kw_hits) + " (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø±ÙƒÙ‘Ø¨Ø©)")

    # Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    req_flags = [x for x in [uni_ok, major_ok, nat_ok] if x is not None]
    all_ok = (len(req_flags) > 0) and all(req_flags)
    verdict = "âœ… Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ø´Ø±ÙˆØ·" if all_ok else "âŒ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚"

    detail = {
        "Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©": "âœ…" if uni_ok else "âŒ",
        "Ø§Ù„ØªØ®ØµØµ": "âœ…" if major_ok else "âŒ",
        "Ø§Ù„Ø¬Ù†Ø³ÙŠØ©": "âœ…" if nat_ok else "âŒ",
        "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©": uni_score,
        "Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ®ØµØµ": major_score,
        "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬Ù†Ø³ÙŠØ©": nat_score,
        "Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø§Ù„ØªØ®ØµØµ": ", ".join(syn_hits) if syn_hits else ""
    }
    return verdict, detail

# ===== Ø®Ø§Ù†Ø§Øª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª =====
st.sidebar.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª")
uni_req = st.sidebar.text_input("ğŸ« Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", "Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ Ø³Ø¹ÙˆØ¯")
major_req = st.sidebar.text_input("ğŸ“š Ø§Ù„ØªØ®ØµØµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨", "Ù†Ø¸Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ©")
major_syn = st.sidebar.text_input("Ù…Ø±Ø§Ø¯ÙØ§Øª Ø§Ù„ØªØ®ØµØµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", "Ø¥Ø¯Ø§Ø±Ø© Ù†Ø¸Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª, MIS, Management Information Systems")
nat_req = st.sidebar.text_input("ğŸŒ Ø§Ù„Ø¬Ù†Ø³ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", "Ø³Ø¹ÙˆØ¯ÙŠ")

# ===== Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª =====
tab1, tab2, tab3 = st.tabs(["ğŸ“‚ Ø±ÙØ¹ CVØ§Øª PDF", "ğŸ“Š Ø±ÙØ¹ Ù…Ù„Ù Excel", "ğŸ“‘ Ø±ÙØ¹ Ù…Ù„Ù CSV"])

results = []

# === ØªØ¨ÙˆÙŠØ¨ 1: PDF ===
with tab1:
    st.subheader("ğŸ“‚ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ CV (PDF)")
    pdf_files = st.file_uploader("Ù…Ù„ÙØ§Øª PDF", type=["pdf"], accept_multiple_files=True)
    if st.button("ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† CVØ§Øª PDF", type="primary"):
        if not pdf_files:
            st.warning("ÙØ¶Ù„Ø§Ù‹ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.")
        else:
            for f in pdf_files:
                raw = extract_pdf_text(f.read())
                verdict, detail = evaluate_cv(raw, uni_req, major_req, major_syn, nat_req)
                st.write(f"**ğŸ“„ {f.name} â†’ {verdict}**")
                results.append({"Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù": f.name, "Ø§Ù„Ù†ØªÙŠØ¬Ø©": verdict, **detail})

# === ØªØ¨ÙˆÙŠØ¨ 2: Excel ===
with tab2:
    st.subheader("ğŸ“Š Ø§Ø±ÙØ¹ÙŠ Ù…Ù„Ù Excel (xlsx)")
    excel_file = st.file_uploader("Ù…Ù„Ù Excel", type=["xlsx"], accept_multiple_files=False)
    if st.button("ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† Excel", type="primary"):
        if not excel_file:
            st.warning("ÙØ¶Ù„Ø§Ù‹ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„Ù Excel.")
        else:
            df = pd.read_excel(excel_file)
            for idx, row in df.iterrows():
                text_raw = " ".join([str(v) for v in row.values if pd.notnull(v)])
                verdict, detail = evaluate_cv(text_raw, uni_req, major_req, major_syn, nat_req)
                st.write(f"**ğŸ“ ØµÙ {idx+1} â†’ {verdict}**")
                results.append({"Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù": f"ØµÙ {idx+1}", "Ø§Ù„Ù†ØªÙŠØ¬Ø©": verdict, **detail})

# === ØªØ¨ÙˆÙŠØ¨ 3: CSV ===
with tab3:
    st.subheader("ğŸ“‘ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„Ù CSV")
    csv_file = st.file_uploader("Ù…Ù„Ù CSV", type=["csv"], accept_multiple_files=False)
    if st.button("ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† CSV", type="primary"):
        if not csv_file:
            st.warning("ÙØ¶Ù„Ø§Ù‹ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„Ù CSV.")
        else:
            df = pd.read_csv(csv_file)
            for idx, row in df.iterrows():
                text_raw = " ".join([str(v) for v in row.values if pd.notnull(v)])
                verdict, detail = evaluate_cv(text_raw, uni_req, major_req, major_syn, nat_req)
                st.write(f"**ğŸ“ ØµÙ {idx+1} â†’ {verdict}**")
                results.append({"Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù": f"ØµÙ {idx+1}", "Ø§Ù„Ù†ØªÙŠØ¬Ø©": verdict, **detail})

# ===== Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ =====
if results:
    df = pd.DataFrame(results)
    st.divider()
    st.dataframe(df, use_container_width=True)
    csv = df.to_csv(index=False).encode('utf-8-sig')
    st.download_button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ€ CSV", csv, "Ù†ØªØ§Ø¦Ø¬_Ø§Ù„ÙØ±Ø².csv", "text/csv")
