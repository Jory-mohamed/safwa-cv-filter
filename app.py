import streamlit as st
import re, unicodedata, io
from pypdf import PdfReader
from rapidfuzz import fuzz

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="ÙÙ„ØªØ±Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©", page_icon="ğŸ—‚ï¸", layout="centered")
st.title("ğŸ—‚ï¸ ÙÙ„ØªØ±Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©")
st.caption("Version: 2.0 â€¢ ÙŠØ¯Ø¹Ù… Ø§Ù„Ø±ÙØ¹ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ + Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠØ© (Fuzzy) + Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª ÙˆØ§Ù„Ø¹ØªØ¨Ø©")

# ===== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© =====
def normalize_ar(text: str) -> str:
    if not text:
        return ""
    text = text.lower()
    text = ''.join(ch for ch in unicodedata.normalize('NFKD', text) if not unicodedata.combining(ch))
    text = re.sub(r"[Ø£Ø¥Ø¢Ù±]", "Ø§", text)
    text = text.replace("Ø©","Ù‡").replace("Ù‰","ÙŠ")
    text = re.sub(r"[^0-9a-z\u0600-\u06FF\s]+", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def extract_pdf_text(file_bytes: bytes) -> str:
    reader = PdfReader(io.BytesIO(file_bytes))
    pages = []
    for p in reader.pages:
        try:
            pages.append(p.extract_text() or "")
        except Exception:
            pages.append("")
    return "\n".join(pages)

# ===== Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© =====
def exact_contains(term: str, text: str) -> (bool, int):
    """Ù…Ø·Ø§Ø¨Ù‚Ø© Ø­Ø±ÙÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠØ¹"""
    if not term.strip():
        return None, 0
    norm_text = normalize_ar(text)
    norm_term = normalize_ar(term)
    found = norm_term in norm_text
    return found, 100 if found else 0

def fuzzy_contains(term: str, text: str, threshold: int = 85) -> (bool, int):
    """Ù…Ø·Ø§Ø¨Ù‚Ø© Ø°ÙƒÙŠØ©: Ù†Ø­Ø³Ø¨ Ø£Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø© Ø¨ÙŠÙ† partial_ratio Ùˆ token_set_ratio"""
    if not term.strip():
        return None, 0
    norm_text = normalize_ar(text)
    norm_term = normalize_ar(term)
    score1 = fuzz.partial_ratio(norm_term, norm_text)
    score2 = fuzz.token_set_ratio(norm_term, norm_text)
    score = max(score1, score2)
    return (score >= threshold), int(score)

def check_with_synonyms(text: str, base_value: str, synonyms: list, use_fuzzy: bool, threshold: int):
    """
    ÙŠØ±Ø¬Ø¹ (ok, best_score, hits)
    - ok: True/False/None
    - best_score: Ø£Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø© ÙˆØµÙ„Ù†Ø§ Ù„Ù‡Ø§
    - hits: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª/Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª Ø§Ù„ØªÙŠ Ø·Ø§Ø¨Ù‚Øª
    """
    if not base_value.strip() and not any(s.strip() for s in synonyms):
        return None, 0, []
    terms = [t for t in [base_value.strip(), *[s.strip() for s in synonyms]] if t]
    best = 0
    hits = []
    # Ø¬Ø±Ù‘Ø¨ ÙƒÙ„ Ù…ØµØ·Ù„Ø­
    for t in terms:
        ok, score = (fuzzy_contains(t, text, threshold) if use_fuzzy else exact_contains(t, text))
        if ok:
            hits.append(f"{t} (score={score})")
            best = max(best, score)
    ok_final = True if hits else False
    return ok_final, best, hits

# ===== ÙˆØ§Ø¬Ù‡Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø´Ø±ÙˆØ· =====
st.subheader("âœ¨ Ø­Ø¯Ø¯ÙŠ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª")
col1, col2, col3 = st.columns(3)
with col1:
    uni_req = st.text_input("ğŸ« Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", placeholder="Ù…Ø«Ø§Ù„: Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ Ø³Ø¹ÙˆØ¯ / KSU")
    uni_syn = st.text_input("Ù…Ø±Ø§Ø¯ÙØ§Øª Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠØŒ Ø§ÙØµÙ„ÙŠ Ø¨ÙÙˆØ§ØµÙ„)", placeholder="KSU, King Saud University")
with col2:
    major_req = st.text_input("ğŸ“š Ø§Ù„ØªØ®ØµØµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨", placeholder="Ù…Ø«Ø§Ù„: Ù†Ø¸Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ© / MIS")
    major_syn = st.text_input("Ù…Ø±Ø§Ø¯ÙØ§Øª Ø§Ù„ØªØ®ØµØµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", placeholder="Ø§Ø¯Ø§Ø±Ø© Ù†Ø¸Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª, MIS, Management Information Systems")
with col3:
    nat_req = st.text_input("ğŸŒ Ø§Ù„Ø¬Ù†Ø³ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", placeholder="Ù…Ø«Ø§Ù„: Ø³Ø¹ÙˆØ¯ÙŠ / Ø³Ø¹ÙˆØ¯ÙŠØ© / Saudi")
    nat_syn = st.text_input("Ù…Ø±Ø§Ø¯ÙØ§Øª Ø§Ù„Ø¬Ù†Ø³ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", placeholder="saudi national")

st.divider()

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
st.subheader("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¯Ù‚Ø©")
c1, c2 = st.columns([1,2])
with c1:
    use_fuzzy = st.checkbox("ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠØ© (Fuzzy)", value=True)
with c2:
    threshold = st.slider("Ø¹ØªØ¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ (ÙƒÙ„Ù…Ø§ Ø²Ø§Ø¯Øª ØµØ§Ø± Ø§Ù„ØªØ´Ø¯Ø¯ Ø£Ø¹Ù„Ù‰)", min_value=60, max_value=95, value=85, step=1)

# ===== Ø±ÙØ¹ Ù…Ù„ÙØ§Øª =====
st.subheader("ğŸ“‚ Ø§Ø±ÙØ¹ÙŠ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ CV Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©")
files = st.file_uploader("Ù…Ù„ÙØ§Øª PDF", type=["pdf"], accept_multiple_files=True)

def evaluate_cv(text_raw: str):
    uni_ok, uni_score, uni_hits     = check_with_synonyms(text_raw, uni_req,  uni_syn.split(",") if uni_syn else [],  use_fuzzy, threshold)
    major_ok, major_score, major_hits = check_with_synonyms(text_raw, major_req, major_syn.split(",") if major_syn else [], use_fuzzy, threshold)
    nat_ok, nat_score, nat_hits     = check_with_synonyms(text_raw, nat_req,  nat_syn.split(",") if nat_syn else [],  use_fuzzy, threshold)

    # Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: ÙƒÙ„ Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† TrueØ› Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„ÙØ§Ø±ØºØ© ØªÙÙ‡Ù…Ù„ (None)
    req_flags = [x for x in [uni_ok, major_ok, nat_ok] if x is not None]
    all_ok = (len(req_flags) > 0) and all(req_flags)
    verdict = "âœ… Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ø´Ø±ÙˆØ·" if all_ok else "âŒ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚"

    detail = [
        ("Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©", uni_ok, uni_score, uni_hits),
        ("Ø§Ù„ØªØ®ØµØµ", major_ok, major_score, major_hits),
        ("Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", nat_ok, nat_score, nat_hits),
    ]
    return verdict, detail

def render_detail(detail):
    for label, ok, score, hits in detail:
        if ok is None:
            st.write(f"**{label}:** â­ï¸ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø´Ø±Ø·")
        else:
            icon = "âœ…" if ok else "âŒ"
            st.write(f"**{label}:** {icon} â€” (score={score})")
            if hits:
                with st.expander(f"Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© ÙÙŠ {label}"):
                    for h in sorted(set(hits)):
                        st.code(h, language="text")

if st.button("ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª", type="primary"):
    if not files:
        st.warning("ÙØ¶Ù„Ø§Ù‹ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.")
    else:
        for i, f in enumerate(files, start=1):
            st.divider()
            st.write(f"**ğŸ“„ Ø§Ù„Ù…Ù„Ù {i}:** `{f.name}`")
            try:
                raw = extract_pdf_text(f.read())
            except Exception as e:
                st.error(f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© `{f.name}`: {e}")
                continue

            verdict, detail = evaluate_cv(raw)
            st.markdown(f"**Ø§Ù„Ù†ØªÙŠØ¬Ø©:** {verdict}")
            render_detail(detail)

st.caption("ğŸ” Ù…Ù„Ø§Ø­Ø¸Ø§Øª: 1) Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù€ PDF ØµÙˆØ±Ø© Ù…Ù…Ø³ÙˆØ­Ø©ØŒ Ù†Ø¶ÙŠÙ OCR Ù„Ø§Ø­Ù‚Ø§Ù‹. 2) Ø¬Ø±Ù‘Ø¨ÙŠ threshold = 80â€“88 Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ù†Ø§Ø³Ø¨Ø©. 3) Ø£Ø¶ÙŠÙÙŠ Ù…Ø±Ø§Ø¯ÙØ§Øª Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¯Ù‚Ø©.")
