import streamlit as st
import re, unicodedata, io
from pypdf import PdfReader
from rapidfuzz import fuzz
import pandas as pd

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="ÙÙ„ØªØ±Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©", page_icon="ğŸ—‚ï¸", layout="centered")
st.title("ğŸ—‚ï¸ ÙÙ„ØªØ±Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©")
st.caption("Version: 2.3 â€¢ 3 Ø®Ø§Ù†Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© + Ù…Ø±Ø§Ø¯ÙØ§Øª Ù„Ù„ØªØ®ØµØµ â€¢ Ø±ÙØ¹ Ù…ØªØ¹Ø¯Ø¯ â€¢ ØªØµØ¯ÙŠØ± CSV")

# ===== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© =====
def normalize_ar(text: str) -> str:
    if not text:
        return ""
    text = text.lower()
    text = ''.join(ch for ch in unicodedata.normalize('NFKD', text) if not unicodedata.combining(ch))
    text = re.sub(r"[Ø£Ø¥Ø¢Ù±]", "Ø§", text)
    text = text.replace("Ø©","Ù‡").replace("Ù‰","ÙŠ")
    text = re.sub(r"[^0-9a-zØ€-Û¿\s]+", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def extract_pdf_text(file_bytes: bytes) -> str:
    reader = PdfReader(io.BytesIO(file_bytes))
    pages = []
    for p in reader.pages:
        try:
            pages.append(p.extract_text() or "")
        except Exception:
            pages.append("")
    return "\n".join(pages)

def fuzzy_match(term: str, text: str, threshold: int = 80) -> (bool, int):
    """Ù…Ø·Ø§Ø¨Ù‚Ø© Ø°ÙƒÙŠØ© (Fuzzy) Ø¨ÙŠÙ† Ø§Ù„Ù…ØµØ·Ù„Ø­ ÙˆØ§Ù„Ù†Øµ"""
    if not term or not term.strip():
        return None, 0
    norm_text = normalize_ar(text)
    norm_term = normalize_ar(term)
    score1 = fuzz.partial_ratio(norm_term, norm_text)
    score2 = fuzz.token_set_ratio(norm_term, norm_text)
    score = max(score1, score2)
    return (score >= threshold), int(score)

# ===== ÙˆØ§Ø¬Ù‡Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª =====
st.subheader("âœ¨ Ø­Ø¯Ø¯ÙŠ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª")

col1, col2, col3 = st.columns(3)
with col1:
    uni_req = st.text_input("ğŸ« Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", placeholder="Ù…Ø«Ø§Ù„: Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ Ø³Ø¹ÙˆØ¯ / KSU")
with col2:
    major_req = st.text_input("ğŸ“š Ø§Ù„ØªØ®ØµØµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨", placeholder="Ù…Ø«Ø§Ù„: Ù†Ø¸Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ© / MIS")
    major_syn = st.text_input("Ù…Ø±Ø§Ø¯ÙØ§Øª Ø§Ù„ØªØ®ØµØµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", placeholder="Ø¥Ø¯Ø§Ø±Ø© Ù†Ø¸Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª, MIS, Management Information Systems")
with col3:
    nat_req = st.text_input("ğŸŒ Ø§Ù„Ø¬Ù†Ø³ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", placeholder="Ù…Ø«Ø§Ù„: Ø³Ø¹ÙˆØ¯ÙŠ / Ø³Ø¹ÙˆØ¯ÙŠØ© / Saudi")

st.divider()

# ===== Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª =====
st.subheader("ğŸ“‚ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ CV Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©")
files = st.file_uploader("Ù…Ù„ÙØ§Øª PDF", type=["pdf"], accept_multiple_files=True)

# ===== Ø§Ù„ØªØ­Ù‚Ù‚ =====
def evaluate_cv(text_raw: str, threshold: int = 80):
    norm_text = normalize_ar(text_raw)

    # Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© ÙˆØ§Ù„Ø¬Ù†Ø³ÙŠØ©: Fuzzy Ø¹Ø§Ø¯ÙŠ
    uni_ok, uni_score = fuzzy_match(uni_req, norm_text, threshold)
    nat_ok, nat_score = fuzzy_match(nat_req, norm_text, threshold)

    # Ø§Ù„ØªØ®ØµØµ: Fuzzy + Ø´Ø±Ø· Ù…Ø±ÙƒÙ‘Ø¨ Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ù†Ø¸Ù… + Ù…Ø¹Ù„ÙˆÙ…Ø§Øª)
    major_ok, major_score = fuzzy_match(major_req, norm_text, threshold)

    syn_hits = []
    if major_syn.strip():
        for s in major_syn.split(","):
            term = s.strip()
            if not term:
                continue
            ok, score = fuzzy_match(term, norm_text, threshold)
            if ok:
                major_ok = True
                major_score = max(major_score, score)
                syn_hits.append(f"{term} (score={score})")
    # ÙƒÙ„Ù…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„ØªØ®ØµØµ (ØªÙ‚Ù„Ù„ Ù‚Ø¨ÙˆÙ„ Ø§Ù„ØºÙ„Ø·)
    base_keywords = ["Ù†Ø¸Ù…", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"]
    kw_hits = [kw for kw in base_keywords if kw in norm_text]
    if len(kw_hits) >= 2:
        major_ok = True
        major_score = max(major_score, 90)
        syn_hits.append(" + ".join(kw_hits) + " (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø±ÙƒÙ‘Ø¨Ø©)")

    req_flags = [x for x in [uni_ok, major_ok, nat_ok] if x is not None]
    all_ok = (len(req_flags) > 0) and all(req_flags)
    verdict = "âœ… Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ø´Ø±ÙˆØ·" if all_ok else "âŒ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚"

    detail = [
        ("Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©", uni_ok, uni_score, []),
        ("Ø§Ù„ØªØ®ØµØµ", major_ok, major_score, syn_hits),
        ("Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", nat_ok, nat_score, []),
    ]
    return verdict, detail

def render_detail(detail):
    for label, ok, score, hits in detail:
        if ok is None:
            st.write(f"**{label}:** â­ï¸ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø´Ø±Ø·")
        else:
            icon = "âœ…" if ok else "âŒ"
            st.write(f"**{label}:** {icon}  (score={score})")
            if hits:
                st.caption("Ù…Ø·Ø§Ø¨Ù‚Ø§Øª: " + ", ".join(hits))

if st.button("ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª", type="primary"):
    if not files:
        st.warning("ÙØ¶Ù„Ø§Ù‹ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.")
    else:
        results = []
        for i, f in enumerate(files, start=1):
            st.divider()
            st.write(f"**ğŸ“„ Ø§Ù„Ù…Ù„Ù {i}:** `{f.name}`")
            try:
                raw = extract_pdf_text(f.read())
            except Exception as e:
                st.error(f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© `{f.name}`: {e}")
                continue

            verdict, detail = evaluate_cv(raw)
            st.markdown(f"**Ø§Ù„Ù†ØªÙŠØ¬Ø©:** {verdict}")
            render_detail(detail)

            results.append({
                "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù": f.name,
                "Ø§Ù„Ù†ØªÙŠØ¬Ø©": verdict,
                "Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©": "âœ…" if detail[0][1] else "âŒ" if detail[0][1] is not None else "â€”",
                "Ø§Ù„ØªØ®ØµØµ": "âœ…" if detail[1][1] else "âŒ" if detail[1][1] is not None else "â€”",
                "Ø§Ù„Ø¬Ù†Ø³ÙŠØ©": "âœ…" if detail[2][1] else "âŒ" if detail[2][1] is not None else "â€”",
                "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©": detail[0][2],
                "Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ®ØµØµ": detail[1][2],
                "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬Ù†Ø³ÙŠØ©": detail[2][2],
            })

        if results:
            df = pd.DataFrame(results)
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ€ CSV",
                data=csv,
                file_name="Ù†ØªØ§Ø¦Ø¬_Ø§Ù„ÙØ±Ø².csv",
                mime="text/csv"
            )

st.caption("ğŸ” Ù…Ù„Ø§Ø­Ø¸Ø©: Ù…Ù„ÙØ§Øª PDF Ø§Ù„Ù…ØµÙˆÙ‘Ø±Ø© (Ø¨Ø¯ÙˆÙ† Ù†Øµ) ØªØ­ØªØ§Ø¬ OCR Ù„Ø§Ø­Ù‚Ø§Ù‹. Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© 80 ÙˆÙŠÙ…ÙƒÙ† ØªØ´Ø¯ÙŠØ¯Ù‡Ø§ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙƒÙˆØ¯ Ù„Ùˆ Ø­Ø¨ÙŠØªÙŠ.")
