import streamlit as st
import re
import unicodedata
from pypdf import PdfReader
import io

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="ÙØ±Ø² Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© - HR Filter", page_icon="ğŸ—‚ï¸", layout="centered")
st.title("ğŸ—‚ï¸ Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙØ±Ø² Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©")
st.caption("ÙŠØªØ­Ù‚Ù‚ Ù…Ù†: **Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ Ø³Ø¹ÙˆØ¯** + **Ù†Ø¸Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ©** + **Ø§Ù„Ø¬Ù†Ø³ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©**")

# --------- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ---------
def normalize_ar(text: str) -> str:
    if not text:
        return ""
    text = text.lower()
    text = ''.join(ch for ch in unicodedata.normalize('NFKD', text) if not unicodedata.combining(ch))
    text = re.sub(r"[Ø£Ø¥Ø¢Ù±]", "Ø§", text)
    text = text.replace("Ø©", "Ù‡").replace("Ù‰", "ÙŠ")
    text = re.sub(r"[^0-9a-z\u0600-\u06FF\s]+", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def extract_pdf_text(file_bytes: bytes) -> str:
    reader = PdfReader(io.BytesIO(file_bytes))
    pages = []
    for p in reader.pages:
        try:
            pages.append(p.extract_text() or "")
        except Exception:
            pages.append("")
    return "\n".join(pages)

# --------- Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ---------
UNI_PATTERNS = [
    r"\bØ¬Ø§Ù…Ø¹Ù‡?\s+Ø§Ù„Ù…Ù„Ùƒ\s+Ø³Ø¹ÙˆØ¯\b",
    r"\bking\s+saud\s+university\b",
    r"\bksu\b"
]
MAJOR_PATTERNS = [
    r"\bÙ†Ø¸Ù…\s+Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\s+Ø§Ù„Ø§Ø¯Ø§Ø±ÙŠ(?:Ù‡|Ø©)?\b",
    r"\bØ§Ø¯Ø§Ø±Ù‡?\s+Ù†Ø¸Ù…\s+Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\b",
    r"\bmis\b",
    r"\bmanagement\s+information\s+systems?\b"
]
NAT_PATTERNS = [
    r"\bØ³Ø¹ÙˆØ¯ÙŠ(?:Ù‡)?\b",
    r"\bsaudi(?:\s+(?:arabia|national))?\b"
]

def find_matches(patterns, text):
    hits = []
    for p in patterns:
        for m in re.findall(p, text, flags=re.IGNORECASE):
            if isinstance(m, tuple):
                m = " ".join([x for x in m if isinstance(x, str)])
            hits.append(m if isinstance(m, str) else "")
    hits = [h.strip() for h in hits if h and h.strip()]
    return (len(hits) > 0), hits

def evaluate_cv(raw_text: str):
    norm = normalize_ar(raw_text)
    uni_ok, uni_hits = find_matches(UNI_PATTERNS, norm)
    major_ok, major_hits = find_matches(MAJOR_PATTERNS, norm)
    nat_ok, nat_hits = find_matches(NAT_PATTERNS, norm)

    all_ok = uni_ok and major_ok and nat_ok
    verdict = "âœ… Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ø´Ø±ÙˆØ·" if all_ok else "âŒ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚"

    detail = [
        ("Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©", uni_ok, uni_hits),
        ("Ø§Ù„ØªØ®ØµØµ", major_ok, major_hits),
        ("Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", nat_ok, nat_hits),
    ]
    return verdict, detail

def render_detail(detail):
    for label, ok, hits in detail:
        st.write(f"**{label}:** {'âœ… Ù…ÙˆØ¬ÙˆØ¯' if ok else 'âŒ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}")
        if hits:
            with st.expander(f"Ø§Ù„Ø£Ù„ÙØ§Ø¸ Ø§Ù„ØªÙŠ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§ ÙÙŠ {label}"):
                for h in sorted(set(hits)):
                    st.code(h, language="text")

# --------- Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (Ø®Ø§Ù†Ø© ÙˆØ­Ø¯Ø©) ---------
st.subheader("âœ¨ Ø§Ø±ÙØ¹ÙŠ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ CV Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©")
files = st.file_uploader("Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙØ§Øª PDF", type=["pdf"], accept_multiple_files=True)

if st.button("ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª", type="primary"):
    if not files:
        st.warning("ÙØ¶Ù„Ø§Ù‹ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.")
    else:
        for idx, f in enumerate(files, start=1):
            st.divider()
            st.write(f"**ğŸ“„ Ø§Ù„Ù…Ù„Ù {idx}:** `{f.name}`")
            try:
                raw = extract_pdf_text(f.read())
            except Exception as e:
                st.error(f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© `{f.name}`: {e}")
                continue

            verdict, detail = evaluate_cv(raw)
            st.markdown(f"**Ø§Ù„Ù†ØªÙŠØ¬Ø©:** {verdict}")
            render_detail(detail)

st.caption("ğŸ” Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ù„Ù Ø§Ù„Ù€ PDF ØµÙˆØ±Ø© Ù…Ù…Ø³ÙˆØ­Ø©ØŒ Ù…Ø§ Ø±Ø§Ø­ ÙŠÙ†Ù‚Ø±Ø£ Ù†ØµÙ‡ Ø¥Ù„Ø§ Ø¨Ø¥Ø¶Ø§ÙØ© OCR Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹.")
