import streamlit as st
import re, unicodedata, io
from pypdf import PdfReader
from rapidfuzz import fuzz

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="ÙÙ„ØªØ±Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©", page_icon="ğŸ—‚ï¸", layout="centered")
st.title("ğŸ—‚ï¸ ÙÙ„ØªØ±Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©")
st.caption("Version: 2.2 â€¢ Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø±ÙƒÙ‘Ø¨Ø© Ù„Ù„ØªØ®ØµØµ + Ù…Ø±ÙˆÙ†Ø© Ø¨Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© ÙˆØ§Ù„Ø¬Ù†Ø³ÙŠØ©")

# ===== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© =====
def normalize_ar(text: str) -> str:
    if not text:
        return ""
    text = text.lower()
    text = ''.join(ch for ch in unicodedata.normalize('NFKD', text) if not unicodedata.combining(ch))
    text = re.sub(r"[Ø£Ø¥Ø¢Ù±]", "Ø§", text)
    text = text.replace("Ø©","Ù‡").replace("Ù‰","ÙŠ")
    text = re.sub(r"[^0-9a-z\u0600-\u06FF\s]+", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def extract_pdf_text(file_bytes: bytes) -> str:
    reader = PdfReader(io.BytesIO(file_bytes))
    pages = []
    for p in reader.pages:
        try:
            pages.append(p.extract_text() or "")
        except Exception:
            pages.append("")
    return "\n".join(pages)

def fuzzy_match(term: str, text: str, threshold: int = 80) -> (bool, int):
    if not term.strip():
        return None, 0
    norm_text = normalize_ar(text)
    norm_term = normalize_ar(term)
    score1 = fuzz.partial_ratio(norm_term, norm_text)
    score2 = fuzz.token_set_ratio(norm_term, norm_text)
    score = max(score1, score2)
    return (score >= threshold), int(score)

# ===== ÙˆØ§Ø¬Ù‡Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª =====
st.subheader("âœ¨ Ø­Ø¯Ø¯ÙŠ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª")

col1, col2, col3 = st.columns(3)
with col1:
    uni_req = st.text_input("ğŸ« Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", placeholder="Ù…Ø«Ø§Ù„: Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ Ø³Ø¹ÙˆØ¯ / KSU")
with col2:
    major_req = st.text_input("ğŸ“š Ø§Ù„ØªØ®ØµØµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨", placeholder="Ù…Ø«Ø§Ù„: Ù†Ø¸Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ© / MIS")
    major_syn = st.text_input("Ù…Ø±Ø§Ø¯ÙØ§Øª Ø§Ù„ØªØ®ØµØµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", placeholder="Ø¥Ø¯Ø§Ø±Ø© Ù†Ø¸Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª, MIS, Management Information Systems")
with col3:
    nat_req = st.text_input("ğŸŒ Ø§Ù„Ø¬Ù†Ø³ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", placeholder="Ù…Ø«Ø§Ù„: Ø³Ø¹ÙˆØ¯ÙŠ / Ø³Ø¹ÙˆØ¯ÙŠØ© / Saudi")

st.divider()

# ===== Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª =====
st.subheader("ğŸ“‚ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ CV Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©")
files = st.file_uploader("Ù…Ù„ÙØ§Øª PDF", type=["pdf"], accept_multiple_files=True)

# ===== Ø§Ù„ØªØ­Ù‚Ù‚ =====
def evaluate_cv(text_raw: str, threshold: int = 80):
    norm_text = normalize_ar(text_raw)

    # Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© ÙˆØ§Ù„Ø¬Ù†Ø³ÙŠØ© Ø¨Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
    uni_ok, uni_score = fuzzy_match(uni_req, norm_text, threshold)
    nat_ok, nat_score = fuzzy_match(nat_req, norm_text, threshold)

    # Ø§Ù„ØªØ®ØµØµ: Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø±ÙƒØ¨Ø© (Ù„Ø§Ø²Ù… ÙƒÙ„Ù…ØªÙŠÙ† Ø£Ùˆ Ø£ÙƒØ«Ø±)
    major_ok, major_score = fuzzy_match(major_req, norm_text, threshold)
    syn_hits = []

    # Ù„Ùˆ Ø­Ø§Ø·Ù‘Ø© Ù…Ø±Ø§Ø¯ÙØ§Øª
    if major_syn.strip():
        for s in major_syn.split(","):
            ok, score = fuzzy_match(s.strip(), norm_text, threshold)
            if ok:
                major_ok = True
                major_score = max(major_score, score)
                syn_hits.append(f"{s.strip()} (score={score})")

    # ÙØ­Øµ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ù…Ø«Ù„Ø§Ù‹: Ù†Ø¸Ù… + Ù…Ø¹Ù„ÙˆÙ…Ø§Øª + Ø§Ø¯Ø§Ø±ÙŠÙ‡/Ø¥Ø¯Ø§Ø±ÙŠØ©)
    base_keywords = ["Ù†Ø¸Ù…", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"]
    kw_hits = [kw for kw in base_keywords if kw in norm_text]
    if len(kw_hits) >= 2:  # Ù„Ù‚Ù‰ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ ÙƒÙ„Ù…ØªÙŠÙ†
        major_ok = True
        major_score = max(major_score, 90)
        syn_hits.append(" ".join(kw_hits) + " (ØªØ±ÙƒÙŠØ¨ÙŠ)")

    # Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    req_flags = [x for x in [uni_ok, major_ok, nat_ok] if x is not None]
    all_ok = (len(req_flags) > 0) and all(req_flags)
    verdict = "âœ… Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ø´Ø±ÙˆØ·" if all_ok else "âŒ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚"

    detail = [
        ("Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©", uni_ok, uni_score, []),
        ("Ø§Ù„ØªØ®ØµØµ", major_ok, major_score, syn_hits),
        ("Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", nat_ok, nat_score, []),
    ]
    return verdict, detail

def render_detail(detail):
    for label, ok, score, hits in detail:
        if ok is None:
            st.write(f"**{label}:** â­ï¸ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø´Ø±Ø·")
        else:
            icon = "âœ…" if ok else "âŒ"
            st.write(f"**{label}:** {icon} (score={score})")
            if hits:
                st.caption("Ù…Ø·Ø§Ø¨Ù‚Ø§Øª: " + ", ".join(hits))

if st.button("ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª", type="primary"):
    if not files:
        st.warning("ÙØ¶Ù„Ø§Ù‹ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙÙ‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.")
    else:
        for i, f in enumerate(files, start=1):
            st.divider()
            st.write(f"**ğŸ“„ Ø§Ù„Ù…Ù„Ù {i}:** `{f.name}`")
            try:
                raw = extract_pdf_text(f.read())
            except Exception as e:
                st.error(f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© `{f.name}`: {e}")
                continue

            verdict, detail = evaluate_cv(raw)
            st.markdown(f"**Ø§Ù„Ù†ØªÙŠØ¬Ø©:** {verdict}")
            render_detail(detail)

st.caption("ğŸ” Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„ØªØ®ØµØµ ÙŠØªØ·Ù„Ø¨ Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø±Ù†Ø© + ÙƒÙ„Ù…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø¹Ù‹Ø§ (Ù†Ø¸Ù… + Ù…Ø¹Ù„ÙˆÙ…Ø§Øª). PDF Ù…ØµÙˆØ± ÙŠØ­ØªØ§Ø¬ OCR Ù„Ø§Ø­Ù‚Ù‹Ø§.")
